{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NOTvDnZytps_"
      },
      "outputs": [],
      "source": [
        "!pip install pandas --quiet\n",
        "!pip install numpy --quiet\n",
        "!pip install matplotlib --quiet\n",
        "!pip install statsmodels --quiet\n",
        "!pip install pmdarima --quiet\n",
        "!pip install xgboost --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install keras --quiet\n",
        "!pip install fbprophet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LItfEzDos6Le"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from pmdarima import auto_arima\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIbg7Tbhs9i_"
      },
      "outputs": [],
      "source": [
        "# Load historical data from a CSV file into a pandas DataFrame\n",
        "train_data = pd.read_csv('/Users/ronangabriel/Downloads/VAL_Forecasting Data (Train).csv')\n",
        "test_data = pd.read_csv('/Users/ronangabriel/Downloads/VAL_Forecasting Data (Test).csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_kxe_QatAOV"
      },
      "outputs": [],
      "source": [
        "# Convert 'Date' column to datetime format\n",
        "train_data['Date'] = pd.to_datetime(train_data['Date'])\n",
        "test_data['Date'] = pd.to_datetime(test_data['Date'])\n",
        "\n",
        "# Set 'Date' column as the index of the DataFrame\n",
        "train_data.set_index('Date', inplace=True)\n",
        "test_data.set_index('Date', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw_WecaWtDqZ"
      },
      "outputs": [],
      "source": [
        "# Views\n",
        "plt.plot(train_data.index, train_data['Views'], label='Train Data')\n",
        "plt.plot(test_data.index, test_data['Views'], label='Test Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Views')\n",
        "plt.title('Views over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H1955a8tFgZ"
      },
      "outputs": [],
      "source": [
        "# Sessions\n",
        "plt.plot(train_data.index, train_data['Sessions'], label='Train Data')\n",
        "plt.plot(test_data.index, test_data['Sessions'], label='Test Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sessions')\n",
        "plt.title('Sessions over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E2CcUSxtHP4"
      },
      "outputs": [],
      "source": [
        "# Views per session\n",
        "plt.plot(train_data.index, train_data['Views per session'], label='Train Data')\n",
        "plt.plot(test_data.index, test_data['Views per session'], label='Test Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Views per session')\n",
        "plt.title('Views per Session over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Be_whM7stI2d"
      },
      "outputs": [],
      "source": [
        "# Total users\n",
        "plt.plot(train_data.index, train_data['Total users'], label='Train Data')\n",
        "plt.plot(test_data.index, test_data['Total users'], label='Test Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total users')\n",
        "plt.title('Total Users over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tolr2by7tLFf"
      },
      "outputs": [],
      "source": [
        "# Engaged sessions/sessions\n",
        "plt.plot(train_data.index, train_data['Engaged sessions/sessions'], label='Train Data')\n",
        "plt.plot(test_data.index, test_data['Engaged sessions/sessions'], label='Test Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Engaged sessions/sessions')\n",
        "plt.title('Engaged Sessions per session over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GIItaqDtNVZ"
      },
      "outputs": [],
      "source": [
        "# Initialize dictionaries to store the forecasts and evaluation metrics for each model\n",
        "forecasts = {}\n",
        "mae_scores = {}\n",
        "mape_scores = {}\n",
        "\n",
        "# Loop through each dependent variable and build and evaluate the models\n",
        "dependent_vars = ['Views', 'Sessions', 'Views per session', 'Total users', 'Engaged sessions/sessions']\n",
        "\n",
        "for var in dependent_vars:\n",
        "    # Exponential Smoothing\n",
        "    model_es = ExponentialSmoothing(train_data[var], trend='add', seasonal='add', freq='D')\n",
        "    model_es_fit = model_es.fit()\n",
        "    forecasts[var + '_ES'] = model_es_fit.forecast(len(test_data))\n",
        "\n",
        "    # ARIMA\n",
        "    model_arima = ARIMA(train_data[var], order=(1, 0, 0), freq='D')\n",
        "    model_arima_fit = model_arima.fit()\n",
        "    forecasts[var + '_ARIMA'] = model_arima_fit.predict(start=len(train_data), end=len(train_data) + len(test_data) - 1)\n",
        "\n",
        "    # Auto ARIMA\n",
        "    model_autoarima = auto_arima(train_data[var], seasonal=False, suppress_warnings=True)\n",
        "    model_autoarima_fit = model_autoarima.fit(train_data[var])\n",
        "    forecasts[var + '_AutoARIMA'] = model_autoarima_fit.predict(n_periods=len(test_data))\n",
        "\n",
        "    # XGBoost\n",
        "    model_xgb = XGBRegressor()\n",
        "    model_xgb.fit(np.arange(len(train_data)).reshape(-1, 1), train_data[var])\n",
        "    forecasts[var + '_XGBoost'] = model_xgb.predict(np.arange(len(train_data), len(train_data) + len(test_data)).reshape(-1, 1))\n",
        "\n",
        "    # LSTM\n",
        "    model_lstm = Sequential()\n",
        "    model_lstm.add(LSTM(100, activation='relu', input_shape=(1, 1)))\n",
        "    model_lstm.add(Dense(1))\n",
        "    model_lstm.compile(optimizer='adam', loss='mse')\n",
        "    model_lstm.fit(np.array(train_data[var]).reshape(-1, 1, 1), np.array(train_data[var]).reshape(-1, 1), epochs=100, verbose=0)\n",
        "    forecasts[var + '_LSTM'] = model_lstm.predict(np.array(test_data[var]).reshape(-1, 1, 1)).flatten()\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae_scores[var + '_ES'] = mean_absolute_error(test_data[var], forecasts[var + '_ES'])\n",
        "    mae_scores[var + '_ARIMA'] = mean_absolute_error(test_data[var], forecasts[var + '_ARIMA'])\n",
        "    mae_scores[var + '_AutoARIMA'] = mean_absolute_error(test_data[var], forecasts[var + '_AutoARIMA'])\n",
        "    mae_scores[var + '_XGBoost'] = mean_absolute_error(test_data[var], forecasts[var + '_XGBoost'])\n",
        "    mae_scores[var + '_LSTM'] = mean_absolute_error(test_data[var], forecasts[var + '_LSTM'])\n",
        "\n",
        "    mape_scores[var + '_ES'] = np.mean(np.abs((test_data[var] - forecasts[var + '_ES']) / test_data[var])) * 100\n",
        "    mape_scores[var + '_ARIMA'] = np.mean(np.abs((test_data[var] - forecasts[var + '_ARIMA']) / test_data[var])) * 100\n",
        "    mape_scores[var + '_AutoARIMA'] = np.mean(np.abs((test_data[var] - forecasts[var + '_AutoARIMA']) / test_data[var])) * 100\n",
        "    mape_scores[var + '_XGBoost'] = np.mean(np.abs((test_data[var] - forecasts[var + '_XGBoost']) / test_data[var])) * 100\n",
        "    mape_scores[var + '_LSTM'] = np.mean(np.abs((test_data[var] - forecasts[var + '_LSTM']) / test_data[var])) * 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oga7mBhRtTX0"
      },
      "outputs": [],
      "source": [
        "# Print the evaluation metrics for each model and dependent variable\n",
        "for var in dependent_vars:\n",
        "    print('---', var, '---')\n",
        "    print('MAE scores:')\n",
        "    for model, score in mae_scores.items():\n",
        "        if var == model.split('_')[0]:\n",
        "            print(model, ':', score)\n",
        "\n",
        "    print('\\nMAPE scores:')\n",
        "    for model, score in mape_scores.items():\n",
        "        if var == model.split('_')[0]:  #\n",
        "            print(model, ':', score)\n",
        "    print('\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}